{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.geometry import MapGeometry\n",
    "from util.load_data import read_records, get_map_from_i_j_to_example_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for_clusters(records, features_dir, i_j_to_example_index_map, map_geometry):\n",
    "    # Returns a numpy array, where each row corresponds to one of the entries\n",
    "    # in `wealth_records`.  Each row contains the average of the features for\n",
    "    # all images in that record's cluster.\n",
    "    # Also returns a list of all clusters for which *no* images were found\n",
    "    # (may be those right on the border).  The prediction data for these ones\n",
    "    # should probably be discarded.\n",
    "\n",
    "    avg_feature_arrays = tuple()\n",
    "    missing_records = {}\n",
    "    records_without_any_images = []\n",
    "    for record_index, record in tqdm(enumerate(records), \n",
    "            desc=\"Loading features for records\", total=len(records)):\n",
    "        \n",
    "        # Find the neighborhood of images for this record's location\n",
    "        # Latitude and longitude are more precise, so if they're available, use\n",
    "        # them for finding the closest set of images in the neighborhood\n",
    "        if 'longitude' in record and 'latitude' in record:\n",
    "            neighborhood = map_geometry.get_image_rect_from_long_lat(\n",
    "                record['longitude'], record['latitude'])\n",
    "        else:\n",
    "            neighborhood = map_geometry.get_image_rect_from_cell_indexes(\n",
    "                record['i'], record['j'])\n",
    "            centroid_longitude, centroid_latitude = (\n",
    "                map_geometry.get_centroid_long_lat(record['i'], record['j']))\n",
    "            # Save references to tthe approximate latitude and longitude,\n",
    "            # in case we want to use it for printing out debugging info later.\n",
    "            record['longitude'] = centroid_longitude\n",
    "            record['latitude'] = centroid_latitude\n",
    "        \n",
    "        # Collect features for all images in the neighborhood\n",
    "        feature_arrays = tuple()\n",
    "        count_missing = 0\n",
    "        for image_i in range(neighborhood['left'], neighborhood['left'] + neighborhood['width']):\n",
    "            for image_j in range(neighborhood['top'], neighborhood['top'] + neighborhood['height']):\n",
    "                if (image_i, image_j) not in i_j_to_example_index_map:\n",
    "                    count_missing += 1\n",
    "                    continue\n",
    "                example_index = i_j_to_example_index_map[(image_i, image_j)]\n",
    "                example_features = np.load(os.path.join(\n",
    "                    features_dir, str(example_index) + \".npz\"))[\"data\"]\n",
    "                feature_arrays += (example_features,)\n",
    "\n",
    "        # Compute the average of all features over all neighbors\n",
    "        if len(feature_arrays) > 0:\n",
    "            cluster_features = np.stack(feature_arrays)\n",
    "            avg_feature_arrays += (np.average(cluster_features, axis=0),)\n",
    "                \n",
    "        if count_missing > 0:\n",
    "            missing_records[record_index] = count_missing\n",
    "            if len(feature_arrays) == 0:\n",
    "                records_without_any_images.append(record_index)\n",
    "\n",
    "    if len(missing_records.keys()) > 0:\n",
    "        print(\"Missing images for %d clusters. \" % (len(missing_records.keys())) +\n",
    "            \". This might not be a bad thing as some clusters may be near a \" +\n",
    "            \"border.  These clusters are:\")\n",
    "        for record_index, missing_count in missing_records.items():\n",
    "            print(\"Record %d (%f, %f): %d images\" % \n",
    "                (record_index, records[record_index]['latitude'],\n",
    "                 records[record_index]['longitude'], missing_count))\n",
    "\n",
    "    avg_features = np.stack(avg_feature_arrays)\n",
    "    return avg_features, records_without_any_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, y): #, Xtest, ytest):\n",
    "    # This method assumes you have already split the data into\n",
    "    # test data and training data, and are only passing in training data.\n",
    "    features = np.array(features)\n",
    "    y = np.array(y)\n",
    "    # Xtest = np.array(Xtest)\n",
    "    # ytest = np.array(ytest)\n",
    "\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    best_alpha_overall = -1\n",
    "    best_score_overall = -1\n",
    "    for i, (train_index, val_index) in enumerate(KFold(n_splits=5, shuffle=True, random_state=443352346).split(features)):\n",
    "\n",
    "        print(\"On fold\", i)\n",
    "        Xtrain = features[train_index]\n",
    "        ytrain = y[train_index]\n",
    "        Xval = features[val_index]\n",
    "        yval = y[val_index]\n",
    "\n",
    "        # Discover best regularization parameter for this fold\n",
    "        model = RidgeCV(alphas=np.logspace(-3, 5, 50, base=10), cv=5)\n",
    "        model.fit(Xtrain, ytrain)\n",
    "        best_alpha = model.alpha_\n",
    "        print(\"Stage I best alpha\", best_alpha)\n",
    "\n",
    "        model = RidgeCV(alphas=np.logspace(np.log10(best_alpha / 2), np.log10(best_alpha * 2), 50, base=10), cv=5)\n",
    "        model.fit(Xtrain, ytrain)\n",
    "        tuned_alpha = model.alpha_\n",
    "        print(\"Stage II best alpha\", tuned_alpha)\n",
    "\n",
    "        # Run on the hold-out test set\n",
    "        ridge = Ridge(alpha=tuned_alpha)\n",
    "        ridge.fit(Xtrain, ytrain)\n",
    "        # score = ridge.score(Xval, yval)\n",
    "        print(\"Test best score:\", ridge.score(Xval, yval))\n",
    "        # Print out predictions!\n",
    "        print(\"Expected\")\n",
    "        for val in yval.tolist():\n",
    "            print(val)\n",
    "        print(\"Actual\")\n",
    "        for val in ridge.predict(Xval).tolist():\n",
    "            print(val)\n",
    "\n",
    "    # Retrain the model on all training data, and dump it to a file for later\n",
    "    # print(\"Saving trained model to file \", output_filename)\n",
    "    # joblib.dump(ridge, output_filename)\n",
    "\n",
    "    return ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_seeds():\n",
    "    # Make sure that every time we get these seeds for splitting, they\n",
    "    # have the same values.\n",
    "    np.random.seed(443352346)\n",
    "    return np.random.randint(0, 2**32 - 1, size=10).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_predictions_for(features_dir, csv, metric_name, metric_column,\n",
    "    i_j_to_example_index_map, map_geometry, v): \n",
    "\n",
    "    if v:\n",
    "        print(\"Preparing for\", metric_name, \"predictions.\")\n",
    "\n",
    "    try:\n",
    "        records = read_records(csv, metric_column)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error: couldn't load CSV file\", csv, \", skipping metric.\")\n",
    "        return\n",
    "\n",
    "    y = [float(r[metric_column]) for r in records]\n",
    "    X, records_to_discard = get_features_for_clusters(\n",
    "        records=records,\n",
    "        features_dir=features_dir,\n",
    "        i_j_to_example_index_map=i_j_to_example_index_map,\n",
    "        map_geometry=map_geometry,\n",
    "    )\n",
    "\n",
    "    # Some of the clusters might not have any images.  Just discard the\n",
    "    # prediction for these ones, don't factor it into the model.  Make\n",
    "    # sure to discard in reverse, so we don't mess up the indexing\n",
    "    # for discarding later records after discarding earlier records.\n",
    "    for i in reversed(records_to_discard):\n",
    "        del(y[i])\n",
    "\n",
    "    # for split_seed in get_random_seeds():\n",
    "    # X_train, X_test, y_train, y_test = (\n",
    "    #     train_test_split(X, y, test_size=0.25, random_state=split_seed))\n",
    "    print(\"Now predicting\", metric_name, \"...\")\n",
    "    wealth_model = predict(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_development(features_dir, country_name, nightlights_csv, nightlights_raster, v):\n",
    "\n",
    "    if v:\n",
    "        print(\"Loading map geometry...\", end=\"\")\n",
    "    map_geometry = MapGeometry(nightlights_raster)\n",
    "    if v:\n",
    "        print(\".\")\n",
    "    i_j_to_example_index_map = get_map_from_i_j_to_example_index(nightlights_csv)\n",
    " \n",
    "    csv_file = lambda basename: os.path.join(\"csv\", country_name + \"_\" + basename + \".csv\")\n",
    "\n",
    "    def run_predictions(csv, metric_name, metric_column):\n",
    "        do_predictions_for(features_dir, csv, metric_name, metric_column,\n",
    "            i_j_to_example_index_map, map_geometry, v)\n",
    "\n",
    "    run_predictions(csv_file(\"DHS_wealth\"), \"wealth\", \"wealth\")\n",
    "    # run_predictions(csv_file(\"cluster_avg_educ_nightlights\"), \"education\", \"education\")\n",
    "    # run_predictions(csv_file(\"cluster_avg_water_nightlights\"), \"water\", \"water\")\n",
    "    # run_predictions(csv_file(\"height_4_age\"), \"child height percentile\", \"height_4_age\")\n",
    "    # run_predictions(csv_file(\"weight_4_age\"), \"child weight percentile\", \"weight_4_age\")\n",
    "    # run_predictions(csv_file(\"weight_4_height\"), \"child weight / height percentile\", \"weight_4_height\")\n",
    "    # run_predictions(csv_file(\"female_bmi\"), \"female BMI\", \"female_bmi\")\n",
    "    # run_predictions(csv_file(\"bed_net_num\"), \"bed net count\", \"bed_net_num\")\n",
    "    # run_predictions(csv_file(\"hemoglobin\"), \"hemoglobin level\", \"hemoglobin\")\n",
    "    # run_predictions(csv_file(\"electricity\"), \"electricity\", \"electricity\")\n",
    "    # run_predictions(csv_file(\"mobile\"), \"mobile phone ownership\", \"mobile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('csv/rwanda_DHS_wealth.csv', 'wealth', 'wealth')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_name = 'rwanda'\n",
    "csv_file = lambda basename: os.path.join(\"csv\", country_name + \"_\" + basename + \".csv\")\n",
    "(csv_file(\"DHS_wealth\"), \"wealth\", \"wealth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_development(\n",
    "        features_dir, # features directory. directory containing features, with one file containing a flat \n",
    "                    # numpy array (.npz) per image\")\n",
    "        args.country_name,  # country_name lower case\n",
    "        args.nightlights_csv, # CSV file where the top row is a header, \n",
    "                              # col 0 (zero-indexed) is the index of the example (basename of feature file), \n",
    "                              # and cols 2 and 3 are the i and j of the cell in the nightlights data\")\n",
    "        args.nightlights_raster, # Raster file of nightlights, used for making a map from latitude and longitude \n",
    "                                # to cell indexes on the map.\"\n",
    "        args.v,                 # verbose\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nightlights_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nightlights_raster = 'F182013.v4c_web.stable_lights.avg_vis.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading map geometry..."
     ]
    }
   ],
   "source": [
    "print(\"Loading map geometry...\", end=\"\")\n",
    "map_geometry = MapGeometry(nightlights_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<util.geometry.MapGeometry at 0x7fbf5d0c3d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
